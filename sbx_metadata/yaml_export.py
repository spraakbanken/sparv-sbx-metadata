"""Export corpus metadata to YAML (SBX specific)."""

import re
from datetime import datetime
from json import JSONDecodeError
from pathlib import Path

import requests
from sparv.api import (
    AnnotationCommonData,
    Config,
    Corpus,
    Export,
    ExportInput,
    Language,
    MarkerOptional,
    OutputMarker,
    SparvErrorMessage,
    exporter,
    get_logger,
    installer,
    uninstaller,
    util,
)

from . import metadata_utils

logger = get_logger(__name__)

# Warning to include at the top of all generated files
WARNING_MESSAGE = (
    "# This file was automatically generated by Sparv. Do not make changes directly to this file as they "
    "will get overwritten.\n"
)

# Max length for short_description (if exceeded, a warning will be issued)
MAX_SHORT_DESC_LEN = 250


@exporter("YAML export of corpus metadata")
def yaml_export(
    out: Export = Export("sbx_metadata/[metadata.id].yaml"),
    corpus_id: Corpus = Corpus(),
    language: Language = Language(),
    metadata: dict = Config("metadata"),
    sentences: AnnotationCommonData = AnnotationCommonData("misc.<sentence>_count"),
    tokens: AnnotationCommonData = AnnotationCommonData("misc.<token>_count"),
    # korp_protected: bool = Config("korp.protected"),
    korp_modes: list = Config("korp.modes"),
    metadata_api: str = Config("sbx_metadata.api_url"),
    md_language: bool = Config("sbx_metadata.language"),
    md_trainingdata: bool = Config("sbx_metadata.trainingdata"),
    md_in_collections: list = Config("sbx_metadata.in_collections"),
    md_unlisted: bool = Config("sbx_metadata.unlisted"),
    md_annotation: dict = Config("sbx_metadata.annotation"),
    md_keywords: list = Config("sbx_metadata.keywords"),
    md_caveats: dict = Config("sbx_metadata.caveats"),
    md_creators: list = Config("sbx_metadata.creators"),
    md_standard_reference: str = Config("sbx_metadata.standard_reference"),
    md_other_references: list = Config("sbx_metadata.other_references"),
    md_intended_uses: dict = Config("sbx_metadata.intended_uses"),
    md_xml_export: str = Config("sbx_metadata.xml_export"),
    md_stats_export: bool = Config("sbx_metadata.stats_export"),
    md_korp: bool = Config("sbx_metadata.korp"),
    md_downloads: list = Config("sbx_metadata.downloads"),
    md_interfaces: list = Config("sbx_metadata.interfaces"),
    md_contact: dict = Config("sbx_metadata.contact_info"),
    md_created: str = Config("sbx_metadata.created"),
    md_updated: str = Config("sbx_metadata.updated"),
    md_doi: str = Config("sbx_metadata.doi"),
) -> None:
    """Export corpus metadata to YAML format."""
    md_obj = {"name": metadata.get("name", {})}

    # Set short description
    set_long_description = True
    if metadata.get("short_description"):
        md_obj["short_description"] = metadata.get("short_description", {})
    # Only long description available, use it for short_description!
    elif metadata.get("description"):
        set_long_description = False
        md_obj["short_description"] = metadata.get("description", {})

    for lang, short_description in md_obj.get("short_description", {}).items():
        # Warn if short description seems to contain HTML
        if re.search(r"<([a-z][a-z0-9]+)\b[^>]*>", short_description):
            logger.warning(
                f"'short_description' ({lang}) seems to contain HTML."
                if set_long_description
                else f"No 'short_description' available and 'description' ({lang}) seems to contain HTML."
            )
        # Warn if short description is too long
        if len(short_description) > MAX_SHORT_DESC_LEN:
            logger.warning(
                f"'short_description' ({lang}) is longer than {MAX_SHORT_DESC_LEN} characters."
                if set_long_description
                else f"No 'short_description' available and 'description' ({lang}) is longer than {MAX_SHORT_DESC_LEN} "
                "characters."
            )

    md_obj["type"] = "corpus"
    md_obj["trainingdata"] = md_trainingdata
    md_obj["unlisted"] = md_unlisted
    md_obj["successors"] = []
    md_obj["language_codes"] = [str(md_language) if md_language else str(language)]

    # Set size
    md_obj["size"] = {"tokens": int(tokens.read()), "sentences": int(sentences.read())}

    md_obj["in_collections"] = md_in_collections

    # Set downloads
    downloads = [
        metadata_utils.make_standard_xml_export(md_xml_export, corpus_id),
        metadata_utils.make_standard_stats_export(md_stats_export, corpus_id),
        *md_downloads,
    ]
    md_obj["downloads"] = [d for d in downloads if d]

    # Set interfaces
    interfaces = []
    interfaces.append(metadata_utils.make_korp(md_korp, corpus_id, korp_modes))
    interfaces.extend(md_interfaces)
    md_obj["interfaces"] = [d for d in interfaces if d]

    # Set contact info
    if md_contact == "sbx-default":
        md_obj["contact_info"] = metadata_utils.SBX_DEFAULT_CONTACT
    else:
        md_obj["contact_info"] = md_contact

    # Add optional metadata fields if they are present
    optional_fields = {
        "annotation": md_annotation,
        "keywords": md_keywords,
        "caveats": md_caveats,
        "creators": md_creators,
        "standard_reference": md_standard_reference,
        "other_references": md_other_references,
        "intended_uses": md_intended_uses,
        "doi": md_doi,
    }
    md_obj.update({key: value for key, value in optional_fields.items() if value})

    # Look up existing DOI
    if not md_doi and metadata_api:
        try:
            url = f"{metadata_api}?resource={corpus_id}"
            logger.info("Looking up existing DOI from API: %s", url)
            response = requests.get(url, timeout=10)
            if existing_doi := response.json().get("doi"):
                md_obj["doi"] = existing_doi
                logger.info("Found existing DOI: %s", existing_doi)
        except requests.RequestException as e:
            logger.warning("Failed to fetch existing DOI from API: %s", e)
        except JSONDecodeError as e:
            logger.warning("Failed to decode JSON response from API: %s", e)

    md_obj["created"] = md_created or datetime.now().strftime("%Y-%m-%d")  # Use today's date as default
    md_obj["updated"] = md_updated or datetime.now().strftime("%Y-%m-%d")  # Use today's date as default

    # Set description
    if set_long_description and metadata.get("description"):
        md_obj["description"] = metadata.get("description", {})
    else:
        md_obj["description"] = {"swe": "", "eng": ""}

    # Remove empty fields
    md_obj = {k: v for k, v in md_obj.items() if v}

    # Write YAML to file
    out_path = Path(out)
    out_path.parent.mkdir(parents=True, exist_ok=True)

    with out_path.open(mode="w", encoding="utf-8") as yaml_file:
        yaml_file.write(WARNING_MESSAGE)
        yaml_file.write(util.misc.dump_yaml(md_obj))

    logger.info("Exported: %s", out)


@installer("Copy YAML metadata to remote host or commit to local Git repository",
           uninstaller="sbx_metadata:uninstall_yaml", priority=-1)
def install_yaml(
    yamlfile: ExportInput = ExportInput("sbx_metadata/[metadata.id].yaml"),
    marker: OutputMarker = OutputMarker("sbx_metadata.install_yaml_export_marker"),
    uninstall_marker: MarkerOptional = MarkerOptional("sbx_metadata.uninstall_yaml_export_marker"),
    export_path: str = Config("sbx_metadata.yaml_export_path"),
    host: str | None = Config("sbx_metadata.yaml_export_host"),
) -> None:
    """Copy YAML metadata to remote host or install to Git repository.

    Args:
        yamlfile: Path to the YAML file.
        marker: Output marker.
        uninstall_marker: Uninstall marker.
        export_path: Path on the remote host.
        host: Host to copy the file to.

    Raises:
        SparvErrorMessage: If neither the host nor export path is set.
    """
    if not export_path:
        raise SparvErrorMessage("'sbx_metadata.yaml_export_path' must be specified. YAML export not installed.")
    if host and host.startswith("git+"):
        util.install.install_git(yamlfile, export_path)
    else:
        filename = Path(yamlfile).name
        remote_file_path = Path(export_path) / filename
        util.install.install_path(yamlfile, host, remote_file_path)
    uninstall_marker.remove()
    marker.write()


@uninstaller("Uninstall YAML metadata")
def uninstall_yaml(
    corpus_id: Corpus = Corpus(),
    marker: OutputMarker = OutputMarker("sbx_metadata.uninstall_yaml_export_marker"),
    install_marker: MarkerOptional = MarkerOptional("sbx_metadata.install_yaml_export_marker"),
    export_path: str = Config("sbx_metadata.yaml_export_path"),
    host: str | None = Config("sbx_metadata.yaml_export_host"),
) -> None:
    """Uninstall YAML metadata.

    Args:
        corpus_id: Corpus ID.
        marker: Output marker.
        install_marker: Install marker.
        export_path: Path on the remote host.
        host: Host on which the file is located.

    Raises:
        SparvErrorMessage: If neither the host nor export path is set.
    """
    if not export_path:
        raise SparvErrorMessage("'sbx_metadata.yaml_export_path' must be specified. YAML export not uninstalled.")
    remote_file_path = Path(export_path) / f"{corpus_id}.yaml"

    if host and host.startswith("git+"):
        util.install.uninstall_git(remote_file_path)
    else:
        util.install.uninstall_path(remote_file_path, host)
    install_marker.remove()
    marker.write()
